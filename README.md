# AI Risk Management Lab (NIST AI RMF)

This repository provides a **hands-on AI Risk Management Lab** using **AWS SageMaker Studio Lab** and Python. The lab follows the **NIST AI Risk Management Framework (AI RMF)** principles, covering **bias detection, adversarial robustness, data privacy, and model drift monitoring**.

## **📌 Overview**
This project demonstrates AI risk management practices by:
- **Training a Fraud Detection AI Model**
- **Detecting Model Bias**
- **Simulating Adversarial AI Attacks**
- **Encrypting AI Data for Privacy**
- **Monitoring Model Drift for Continuous AI Risk Assessment**

## **📂 Repository Structure**
📂 AI-Risk-Management-Lab
│── 📄 AI_Risk_Management_Lab.ipynb     # Jupyter Notebook with full implementation
│── 📄 train_model.py                   # Python script for training AI model
│── 📄 bias_detection.py                # Python script for bias analysis
│── 📄 adversarial_attack.py            # Python script for adversarial testing
│── 📄 data_encryption.py               # Python script for AI data encryption
│── 📄 model_drift.py                   # Python script for detecting model drift
│── 📄 README.md                        # Documentation (this file)
│── 📄 requirements.txt                 # Required Python libraries

## **🛠 Setup Instructions**
### **1️⃣ Clone the Repository**
```bash
git clone https://github.com/YOUR_USERNAME/AI-Risk-Management-Lab.git
cd AI-Risk-Management-Lab

