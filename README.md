# AI Risk Management Lab (NIST AI RMF)

This repository provides a **hands-on AI Risk Management Lab** using **AWS SageMaker Studio Lab** and Python. The lab follows the **NIST AI Risk Management Framework (AI RMF)** principles, covering **bias detection, adversarial robustness, data privacy, and model drift monitoring**.

## **ğŸ“Œ Overview**
This project demonstrates AI risk management practices by:
- **Training a Fraud Detection AI Model**
- **Detecting Model Bias**
- **Simulating Adversarial AI Attacks**
- **Encrypting AI Data for Privacy**
- **Monitoring Model Drift for Continuous AI Risk Assessment**

## **ğŸ“‚ Repository Structure**
ğŸ“‚ AI-Risk-Management-Lab
â”‚â”€â”€ ğŸ“„ AI_Risk_Management_Lab.ipynb     # Jupyter Notebook with full implementation
â”‚â”€â”€ ğŸ“„ train_model.py                   # Python script for training AI model
â”‚â”€â”€ ğŸ“„ bias_detection.py                # Python script for bias analysis
â”‚â”€â”€ ğŸ“„ adversarial_attack.py            # Python script for adversarial testing
â”‚â”€â”€ ğŸ“„ data_encryption.py               # Python script for AI data encryption
â”‚â”€â”€ ğŸ“„ model_drift.py                   # Python script for detecting model drift
â”‚â”€â”€ ğŸ“„ README.md                        # Documentation (this file)
â”‚â”€â”€ ğŸ“„ requirements.txt                 # Required Python libraries

## **ğŸ›  Setup Instructions**
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/YOUR_USERNAME/AI-Risk-Management-Lab.git
cd AI-Risk-Management-Lab

